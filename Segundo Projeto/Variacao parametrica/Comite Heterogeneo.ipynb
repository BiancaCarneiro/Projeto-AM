{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variação Paramétrica do SVM\n",
    "\n",
    "\n",
    "# Passo 1: Preparando o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ORIGINAL = \"../datasets/data_normalizada.csv\"\n",
    "DATASET_SMOTE = \"../datasets/data_smote.csv\"\n",
    "DATASET_UNDER = \"../datasets/data_under.csv\"\n",
    "DATASET_TESTE = \"../datasets/data_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv(DATASET_ORIGINAL)\n",
    "df_smote: pd.DataFrame = pd.read_csv(DATASET_SMOTE)\n",
    "df_under: pd.DataFrame = pd.read_csv(DATASET_UNDER)\n",
    "df_test: pd.DataFrame = pd.read_csv(DATASET_TESTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6819 entries, 0 to 6818\n",
      "Data columns (total 94 columns):\n",
      " #   Column                                                   Non-Null Count  Dtype  \n",
      "---  ------                                                   --------------  -----  \n",
      " 0   Bankrupt?                                                6819 non-null   int64  \n",
      " 1   ROA(C) before interest and depreciation before interest  6819 non-null   float64\n",
      " 2   ROA(A) before interest and % after tax                   6819 non-null   float64\n",
      " 3   ROA(B) before interest and depreciation after tax        6819 non-null   float64\n",
      " 4   Operating Gross Margin                                   6819 non-null   float64\n",
      " 5   Realized Sales Gross Margin                              6819 non-null   float64\n",
      " 6   Operating Profit Rate                                    6819 non-null   float64\n",
      " 7   Pre-tax net Interest Rate                                6819 non-null   float64\n",
      " 8   After-tax net Interest Rate                              6819 non-null   float64\n",
      " 9   Non-industry income and expenditure/revenue              6819 non-null   float64\n",
      " 10  Continuous interest rate (after tax)                     6819 non-null   float64\n",
      " 11  Operating Expense Rate                                   6819 non-null   float64\n",
      " 12  Research and development expense rate                    6819 non-null   float64\n",
      " 13  Cash flow rate                                           6819 non-null   float64\n",
      " 14  Interest-bearing debt interest rate                      6819 non-null   float64\n",
      " 15  Tax rate (A)                                             6819 non-null   float64\n",
      " 16  Net Value Per Share (B)                                  6819 non-null   float64\n",
      " 17  Net Value Per Share (A)                                  6819 non-null   float64\n",
      " 18  Net Value Per Share (C)                                  6819 non-null   float64\n",
      " 19  Persistent EPS in the Last Four Seasons                  6819 non-null   float64\n",
      " 20  Cash Flow Per Share                                      6819 non-null   float64\n",
      " 21  Revenue Per Share (Yuan ¥)                               6819 non-null   float64\n",
      " 22  Operating Profit Per Share (Yuan ¥)                      6819 non-null   float64\n",
      " 23  Per Share Net profit before tax (Yuan ¥)                 6819 non-null   float64\n",
      " 24  Realized Sales Gross Profit Growth Rate                  6819 non-null   float64\n",
      " 25  Operating Profit Growth Rate                             6819 non-null   float64\n",
      " 26  After-tax Net Profit Growth Rate                         6819 non-null   float64\n",
      " 27  Regular Net Profit Growth Rate                           6819 non-null   float64\n",
      " 28  Continuous Net Profit Growth Rate                        6819 non-null   float64\n",
      " 29  Total Asset Growth Rate                                  6819 non-null   float64\n",
      " 30  Net Value Growth Rate                                    6819 non-null   float64\n",
      " 31  Total Asset Return Growth Rate Ratio                     6819 non-null   float64\n",
      " 32  Cash Reinvestment %                                      6819 non-null   float64\n",
      " 33  Current Ratio                                            6819 non-null   float64\n",
      " 34  Quick Ratio                                              6819 non-null   float64\n",
      " 35  Interest Expense Ratio                                   6819 non-null   float64\n",
      " 36  Total debt/Total net worth                               6819 non-null   float64\n",
      " 37  Debt ratio %                                             6819 non-null   float64\n",
      " 38  Net worth/Assets                                         6819 non-null   float64\n",
      " 39  Long-term fund suitability ratio (A)                     6819 non-null   float64\n",
      " 40  Borrowing dependency                                     6819 non-null   float64\n",
      " 41  Contingent liabilities/Net worth                         6819 non-null   float64\n",
      " 42  Operating profit/Paid-in capital                         6819 non-null   float64\n",
      " 43  Net profit before tax/Paid-in capital                    6819 non-null   float64\n",
      " 44  Inventory and accounts receivable/Net value              6819 non-null   float64\n",
      " 45  Total Asset Turnover                                     6819 non-null   float64\n",
      " 46  Accounts Receivable Turnover                             6819 non-null   float64\n",
      " 47  Average Collection Days                                  6819 non-null   float64\n",
      " 48  Inventory Turnover Rate (times)                          6819 non-null   float64\n",
      " 49  Fixed Assets Turnover Frequency                          6819 non-null   float64\n",
      " 50  Net Worth Turnover Rate (times)                          6819 non-null   float64\n",
      " 51  Revenue per person                                       6819 non-null   float64\n",
      " 52  Operating profit per person                              6819 non-null   float64\n",
      " 53  Allocation rate per person                               6819 non-null   float64\n",
      " 54  Working Capital to Total Assets                          6819 non-null   float64\n",
      " 55  Quick Assets/Total Assets                                6819 non-null   float64\n",
      " 56  Current Assets/Total Assets                              6819 non-null   float64\n",
      " 57  Cash/Total Assets                                        6819 non-null   float64\n",
      " 58  Quick Assets/Current Liability                           6819 non-null   float64\n",
      " 59  Cash/Current Liability                                   6819 non-null   float64\n",
      " 60  Current Liability to Assets                              6819 non-null   float64\n",
      " 61  Operating Funds to Liability                             6819 non-null   float64\n",
      " 62  Inventory/Working Capital                                6819 non-null   float64\n",
      " 63  Inventory/Current Liability                              6819 non-null   float64\n",
      " 64  Current Liabilities/Liability                            6819 non-null   float64\n",
      " 65  Working Capital/Equity                                   6819 non-null   float64\n",
      " 66  Current Liabilities/Equity                               6819 non-null   float64\n",
      " 67  Long-term Liability to Current Assets                    6819 non-null   float64\n",
      " 68  Retained Earnings to Total Assets                        6819 non-null   float64\n",
      " 69  Total income/Total expense                               6819 non-null   float64\n",
      " 70  Total expense/Assets                                     6819 non-null   float64\n",
      " 71  Current Asset Turnover Rate                              6819 non-null   float64\n",
      " 72  Quick Asset Turnover Rate                                6819 non-null   float64\n",
      " 73  Working capitcal Turnover Rate                           6819 non-null   float64\n",
      " 74  Cash Turnover Rate                                       6819 non-null   float64\n",
      " 75  Cash Flow to Sales                                       6819 non-null   float64\n",
      " 76  Fixed Assets to Assets                                   6819 non-null   float64\n",
      " 77  Current Liability to Liability                           6819 non-null   float64\n",
      " 78  Current Liability to Equity                              6819 non-null   float64\n",
      " 79  Equity to Long-term Liability                            6819 non-null   float64\n",
      " 80  Cash Flow to Total Assets                                6819 non-null   float64\n",
      " 81  Cash Flow to Liability                                   6819 non-null   float64\n",
      " 82  CFO to Assets                                            6819 non-null   float64\n",
      " 83  Cash Flow to Equity                                      6819 non-null   float64\n",
      " 84  Current Liability to Current Assets                      6819 non-null   float64\n",
      " 85  Net Income to Total Assets                               6819 non-null   float64\n",
      " 86  Total assets to GNP price                                6819 non-null   float64\n",
      " 87  No-credit Interval                                       6819 non-null   float64\n",
      " 88  Gross Profit to Sales                                    6819 non-null   float64\n",
      " 89  Net Income to Stockholder's Equity                       6819 non-null   float64\n",
      " 90  Liability to Equity                                      6819 non-null   float64\n",
      " 91  Degree of Financial Leverage (DFL)                       6819 non-null   float64\n",
      " 92  Interest Coverage Ratio (Interest expense to EBIT)       6819 non-null   float64\n",
      " 93  Equity to Liability                                      6819 non-null   float64\n",
      "dtypes: float64(93), int64(1)\n",
      "memory usage: 4.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 2: Definição do Campo de busca\n",
    "\n",
    "Aqui é definido os parâmetros que serão testados pelo modelo. \n",
    "\n",
    "Segue abaixo uma breve explicação dos parâmetros testados para o SVM:\n",
    "\n",
    " - C (float, default=1.0): Regularização, quanto maior, mais fraca é a força de regularização\n",
    " - kernel (\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\" ou função, default=\"rbf\"): kernel usado no algorítmo\n",
    " - degree (int, default=3): apenas para o kernel = poly\n",
    " - gamma (\"scale\", \"auto\" ou float, default=\"scale\"): coeficiente do kernel para \"rbf\", \"poly\" e \"sigmoid\".\n",
    " - coef0 (float, default=0.0): Termo independente na função do kernel, apenas para os kernels \"poly\" e \"sigmoid\"\n",
    " - tol (float, default=1e-3): tolerância para a parada\n",
    "\n",
    "Como há parâmetros que apenas funcionam para Kernels espeíficos, vamos separar os testes por Kernel pois o algorítmo de escolha de parâmetros será o GridSearchCV, que olha para todas as possibilidades e não faz sentido testar um modelo SVM com kernel linear com diferentes valores de degree, por exemplo.\n",
    "\n",
    "Segue abaixo uma breve explicação dos parâmetros testados para a MLP:\n",
    "\n",
    " - activation (\"identity\", \"logistic\", \"tanh\", \"relu\", default=\"relu\") : função de ativação\n",
    " - solver (\"lbfgs\", \"sgd\", \"adam\", default=\"adam\"): método para alterar os pesos\n",
    " - alpha (float, default=0.0001): Força do termo de regularização\n",
    " - learning_rate (\"constant\", \"invscaling\", \"adaptive\", default=\"constant\"): taxa de aprendizagem\n",
    " - learning_rate_init (float, default=0.001): valor inicial do learning rate\n",
    " - max_iter (int, default=200): número máximo de iterações, representa o número de épocas para \"sgd\" e \"adam\"\n",
    " - tol (float, default=1e-4): tolerância para a otimização\n",
    " - warm_start (bool, default=False): se True reusa a última chamada.\n",
    "\n",
    "Caso seja observado que o melhor método é o adam, também testaramos diferentes valores de beta_1, beta_2 e epsilon.\n",
    "\n",
    "Além disso a MLP terá valores fixos:\n",
    " - early_stopping = True\n",
    " - validation_fraction = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = {\n",
    "    \"svm__C\": [0.5, 1.0, 1.5],\n",
    "    \"svm__kernel\": [\"linear\"],\n",
    "    # \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"mlp__alpha\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"mlp__warm_start\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"poly\"],\n",
    "    # \"svm__degree\": [2, 3, 4, 5],\n",
    "    # \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "    # \"svm__coef0\": [0.0, 0.1, 0.5, 1.0],\n",
    "    # \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"mlp__alpha\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"mlp__warm_start\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"rbf\"],\n",
    "    # \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "    # \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"mlp__alpha\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"mlp__warm_start\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sigmoid = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"sigmoid\"],\n",
    "    # \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "    # \"svm__coef0\": [0.0, 0.1, 0.5, 1.0],\n",
    "    # \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"mlp__alpha\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"mlp__warm_start\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 3: Definindo a Busca por Parâmetros\n",
    "\n",
    "Nesse passo é usado o algorítmo GridSearchCV para escolher os melhores parâmetros, já que ele testa todas as possibilidades.\n",
    "\n",
    "Para ele, foi definido:\n",
    "\n",
    "n_jobs=-1: para utilizarmos todos os processadores possíveis e otimizar a execução;\n",
    "cv=5: para fazer um KFold com 5 folds, dividindo o dataset em 5 partes;\n",
    "scoring=\"f1\": para escolher os melhores parâmetros a partir do f1, por ser um dataset desbalanceado;\n",
    "error_score='raise': para propagar possíveis erros no treinamento com dado conjunto de parâmentros e parar o teste\n",
    "\n",
    "Comparações de performance serão feitas nas próximas etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMSearch(search_params: list[list], X_train: np.ndarray, X_test:  np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> list:\n",
    "    bests = []\n",
    "    for params in search_params:\n",
    "        \n",
    "        svm_clf = SVC(probability=True, random_state=42)\n",
    "        mlp_clf = MLPClassifier(random_state=42)\n",
    "        \n",
    "        voting_clf = VotingClassifier(estimators=[('svm', svm_clf), ('mlp', mlp_clf)], voting='soft')\n",
    "\n",
    "        \n",
    "        print(f\"Buscando com os parametros {params}\")\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=voting_clf, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "        best = grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        print(f\"Melhores parâmetros: {best.best_params_}\")\n",
    "        print(f\"Melhor f1: {best.best_score_}\")\n",
    "        \n",
    "        print(classification_report(y_test, best.predict(X_test)))\n",
    "        bests.append(best)\n",
    "    \n",
    "    return bests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 4: Realizando a busca para o dataset normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:, 1:], df.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando com os parametros {'svm__C': [0.5, 1.0, 1.5], 'svm__kernel': ['linear'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__kernel': 'linear'}\n",
      "Melhor f1: 0.9684671210343583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.50      0.01      0.02        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.73      0.51      0.50      2728\n",
      "weighted avg       0.95      0.97      0.95      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['poly'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.1, 'svm__kernel': 'poly'}\n",
      "Melhor f1: 0.9687116198118643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.00      0.00      0.00        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.48      0.50      0.49      2728\n",
      "weighted avg       0.93      0.97      0.95      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['rbf'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 2.0, 'svm__kernel': 'rbf'}\n",
      "Melhor f1: 0.9684668225010524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.44      0.09      0.15        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.71      0.54      0.56      2728\n",
      "weighted avg       0.95      0.97      0.95      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['sigmoid'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__kernel': 'sigmoid'}\n",
      "Melhor f1: 0.9696896149218887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.53      0.10      0.17        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.75      0.55      0.57      2728\n",
      "weighted avg       0.96      0.97      0.96      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bests = SVMSearch(\n",
    "    [\n",
    "        svm_linear,\n",
    "        svm_poly,\n",
    "        svm_rbf,\n",
    "        svm_sigmoid\n",
    "    ],\n",
    "    X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos tiveram resultados muito parecidos, mas podemos ver que 'mlp__alpha': 0.01, 'mlp__warm_start': True e 'mlp__solver': 'sgd' foram o melhor em todos os casos, então vamos fixar eles. Além disso, o kernel \"poly\" teve precision e recall iguais a zero na segunda classe, então não vamos continuar os testes com ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_ = {\n",
    "    \"svm__C\": [0.5, 1.0, 1.5],\n",
    "    \"svm__kernel\": [\"linear\"],\n",
    "    \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-2],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_ = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"rbf\"],\n",
    "    \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-2],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sigmoid_ = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"sigmoid\"],\n",
    "    \"svm__coef0\": [0.0, 0.1, 0.5, 1.0],\n",
    "    \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-2],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando com os parametros {'svm__C': [0.5, 1.0, 1.5], 'svm__kernel': ['linear'], 'svm__tol': [0.01, 0.001, 0.0001], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.01], 'mlp__warm_start': [True]}\n",
      "Melhores parâmetros: {'mlp__activation': 'logistic', 'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__kernel': 'linear', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.9687116198118643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       1.00      0.01      0.02        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.98      0.51      0.50      2728\n",
      "weighted avg       0.97      0.97      0.95      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['rbf'], 'svm__tol': [0.01, 0.001, 0.0001], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.01], 'mlp__warm_start': [True]}\n",
      "Melhores parâmetros: {'mlp__activation': 'logistic', 'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 2.0, 'svm__kernel': 'rbf', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.9696902119885005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.45      0.05      0.10        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.71      0.53      0.54      2728\n",
      "weighted avg       0.95      0.97      0.95      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['sigmoid'], 'svm__coef0': [0.0, 0.1, 0.5, 1.0], 'svm__tol': [0.01, 0.001, 0.0001], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.01], 'mlp__warm_start': [True]}\n",
      "Melhores parâmetros: {'mlp__activation': 'relu', 'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__coef0': 0.0, 'svm__kernel': 'sigmoid', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.9696896149218887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.53      0.10      0.17        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.75      0.55      0.57      2728\n",
      "weighted avg       0.96      0.97      0.96      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bests = SVMSearch(\n",
    "    [\n",
    "        svm_linear_,\n",
    "        svm_rbf_,\n",
    "        svm_sigmoid_\n",
    "    ],\n",
    "    X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos tiveram resultados muito parecidos, mas podemos ver que 'svm__tol': 0.01 foi o melhor em todos os casos, então vamos fixar ele. Além disso, o kernel \"linear\" não conseguiu diferenciar bem as classes, então vamos excluir ele. Também, só tivemos dois valores para a função de ativação, vamos diminuir nosso espaço de busca para eles. Também, novamente, o melhor valor para o svm__coef0 foi 0, então vamos fixar ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_ = {\n",
    "    \"svm__C\": [1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"rbf\"],\n",
    "    \"svm__tol\": [1e-2],\n",
    "    \"mlp__activation\": [\"logistic\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-2],\n",
    "    \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__max_iter\": [100, 200, 300],\n",
    "    \"mlp__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sigmoid_ = {\n",
    "    \"svm__C\": [1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"sigmoid\"],\n",
    "    \"svm__coef0\": [0.0],\n",
    "    \"svm__tol\": [1e-2],\n",
    "    \"mlp__activation\": [\"logistic\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-2],\n",
    "    \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__max_iter\": [100, 200, 300],\n",
    "    \"mlp__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando com os parametros {'svm__C': [1.0, 1.5, 2.0], 'svm__kernel': ['rbf'], 'svm__tol': [0.01], 'mlp__activation': ['logistic', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.01], 'mlp__learning_rate': ['constant', 'invscaling', 'adaptive'], 'mlp__learning_rate_init': [0.01, 0.001, 0.0001], 'mlp__max_iter': [100, 200, 300], 'mlp__tol': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True]}\n",
      "Melhores parâmetros: {'mlp__activation': 'logistic', 'mlp__alpha': 0.01, 'mlp__learning_rate': 'invscaling', 'mlp__learning_rate_init': 0.001, 'mlp__max_iter': 100, 'mlp__solver': 'sgd', 'mlp__tol': 0.01, 'mlp__warm_start': True, 'svm__C': 2.0, 'svm__kernel': 'rbf', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.9701789110102068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.43      0.03      0.06        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.70      0.52      0.52      2728\n",
      "weighted avg       0.95      0.97      0.95      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [1.0, 1.5, 2.0], 'svm__kernel': ['sigmoid'], 'svm__coef0': [0.0], 'svm__tol': [0.01], 'mlp__activation': ['logistic', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.01], 'mlp__learning_rate': ['constant', 'invscaling', 'adaptive'], 'mlp__learning_rate_init': [0.01, 0.001, 0.0001], 'mlp__max_iter': [100, 200, 300], 'mlp__tol': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True]}\n",
      "Melhores parâmetros: {'mlp__activation': 'relu', 'mlp__alpha': 0.01, 'mlp__learning_rate': 'constant', 'mlp__learning_rate_init': 0.01, 'mlp__max_iter': 100, 'mlp__solver': 'sgd', 'mlp__tol': 0.01, 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__coef0': 0.0, 'svm__kernel': 'sigmoid', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.9696896149218887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2637\n",
      "           1       0.53      0.10      0.17        91\n",
      "\n",
      "    accuracy                           0.97      2728\n",
      "   macro avg       0.75      0.55      0.57      2728\n",
      "weighted avg       0.96      0.97      0.96      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bests = SVMSearch(\n",
    "    [\n",
    "        svm_rbf_,\n",
    "        svm_sigmoid_\n",
    "    ],\n",
    "    X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando também a classe 1, o melhor modelo é com os parâmetros {'mlp__activation': 'relu', 'mlp__alpha': 0.01, 'mlp__learning_rate': 'constant', 'mlp__learning_rate_init': 0.01, 'mlp__max_iter': 100, 'mlp__solver': 'sgd', 'mlp__tol': 0.01, 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__coef0': 0.0, 'svm__kernel': 'sigmoid', 'svm__tol': 0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 5: Realizando a busca para o dataset smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_smote.iloc[:, 1:], df_smote.iloc[:, 0]\n",
    "X_test, y_test = df_test.iloc[:, 1:], df_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando com os parametros {'svm__C': [0.5, 1.0, 1.5], 'svm__kernel': ['linear'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'lbfgs', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__kernel': 'linear'}\n",
      "Melhor f1: 0.9854869674664627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2637\n",
      "           1       0.39      0.45      0.42        91\n",
      "\n",
      "    accuracy                           0.96      2728\n",
      "   macro avg       0.69      0.71      0.70      2728\n",
      "weighted avg       0.96      0.96      0.96      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['poly'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.001, 'mlp__solver': 'adam', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__kernel': 'poly'}\n",
      "Melhor f1: 0.985992177293439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2637\n",
      "           1       0.39      0.43      0.41        91\n",
      "\n",
      "    accuracy                           0.96      2728\n",
      "   macro avg       0.68      0.70      0.69      2728\n",
      "weighted avg       0.96      0.96      0.96      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['rbf'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'lbfgs', 'mlp__warm_start': True, 'svm__C': 2.0, 'svm__kernel': 'rbf'}\n",
      "Melhor f1: 0.9856130707707994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2637\n",
      "           1       0.38      0.44      0.41        91\n",
      "\n",
      "    accuracy                           0.96      2728\n",
      "   macro avg       0.68      0.71      0.69      2728\n",
      "weighted avg       0.96      0.96      0.96      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['sigmoid'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.0001, 'mlp__solver': 'lbfgs', 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__kernel': 'sigmoid'}\n",
      "Melhor f1: 0.9853607048402001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      2637\n",
      "           1       0.39      0.46      0.42        91\n",
      "\n",
      "    accuracy                           0.96      2728\n",
      "   macro avg       0.69      0.72      0.70      2728\n",
      "weighted avg       0.96      0.96      0.96      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bests = SVMSearch(\n",
    "    [\n",
    "        svm_linear,\n",
    "        svm_poly,\n",
    "        svm_rbf,\n",
    "        svm_sigmoid\n",
    "    ],\n",
    "    X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos tiveram resultados muito parecidos, para próximos testes, vamos fixar 'mlp__alpha': 0.0001, 'mlp__solver': 'lbfgs', 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__kernel': 'sigmoid', que foi um pouco melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sigmoid_ = {\n",
    "    \"svm__C\": [1.0],\n",
    "    \"svm__kernel\": [\"sigmoid\"],\n",
    "    \"svm__coef0\": [0.0, 0.5, 1],\n",
    "    \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"lbfgs\"],\n",
    "    \"mlp__alpha\": [1e-4],\n",
    "    \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando com os parametros {'svm__C': [1.0], 'svm__kernel': ['sigmoid'], 'svm__coef0': [0.0, 0.5, 1], 'svm__tol': [0.01, 0.001, 0.0001], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__solver': ['lbfgs'], 'mlp__alpha': [0.0001], 'mlp__learning_rate': ['constant', 'invscaling', 'adaptive'], 'mlp__warm_start': [True]}\n",
      "Melhores parâmetros: {'mlp__activation': 'relu', 'mlp__alpha': 0.0001, 'mlp__learning_rate': 'constant', 'mlp__solver': 'lbfgs', 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__coef0': 0.5, 'svm__kernel': 'sigmoid', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.9854868878054998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      2637\n",
      "           1       0.39      0.46      0.42        91\n",
      "\n",
      "    accuracy                           0.96      2728\n",
      "   macro avg       0.69      0.72      0.70      2728\n",
      "weighted avg       0.96      0.96      0.96      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bests = SVMSearch(\n",
    "    [\n",
    "        svm_sigmoid_\n",
    "    ],\n",
    "    X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, o melhor modelo foi: {'mlp__activation': 'relu', 'mlp__alpha': 0.0001, 'mlp__learning_rate': 'constant', 'mlp__solver': 'lbfgs', 'mlp__warm_start': True, 'svm__C': 1.0, 'svm__coef0': 0.5, 'svm__kernel': 'sigmoid', 'svm__tol': 0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 6: Realizando a busca para o dataset under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_under.iloc[:, 1:], df_under.iloc[:, 0]\n",
    "X_test, y_test = df_test.iloc[:, 1:], df_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando com os parametros {'svm__C': [0.5, 1.0, 1.5], 'svm__kernel': ['linear'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 1.5, 'svm__kernel': 'linear'}\n",
      "Melhor f1: 0.8490950226244344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      2637\n",
      "           1       0.14      0.86      0.24        91\n",
      "\n",
      "    accuracy                           0.82      2728\n",
      "   macro avg       0.57      0.84      0.57      2728\n",
      "weighted avg       0.97      0.82      0.88      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['poly'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__kernel': 'poly'}\n",
      "Melhor f1: 0.8566365007541478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      2637\n",
      "           1       0.16      0.85      0.28        91\n",
      "\n",
      "    accuracy                           0.85      2728\n",
      "   macro avg       0.58      0.85      0.60      2728\n",
      "weighted avg       0.97      0.85      0.90      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['rbf'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.1, 'svm__kernel': 'rbf'}\n",
      "Melhor f1: 0.8450226244343891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91      2637\n",
      "           1       0.16      0.90      0.27        91\n",
      "\n",
      "    accuracy                           0.84      2728\n",
      "   macro avg       0.58      0.87      0.59      2728\n",
      "weighted avg       0.97      0.84      0.89      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['sigmoid'], 'mlp__solver': ['lbfgs', 'sgd', 'adam'], 'mlp__alpha': [0.01, 0.001, 0.0001], 'mlp__warm_start': [True, False]}\n",
      "Melhores parâmetros: {'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 1.5, 'svm__kernel': 'sigmoid'}\n",
      "Melhor f1: 0.8450980392156863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      2637\n",
      "           1       0.15      0.88      0.26        91\n",
      "\n",
      "    accuracy                           0.83      2728\n",
      "   macro avg       0.57      0.85      0.58      2728\n",
      "weighted avg       0.97      0.83      0.88      2728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bests = SVMSearch(\n",
    "    [\n",
    "        svm_linear,\n",
    "        svm_poly,\n",
    "        svm_rbf,\n",
    "        svm_sigmoid\n",
    "    ],\n",
    "    X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados dos modelos foram muito próximos, vamos fixar 'mlp__alpha': 0.01, 'mlp__solver': 'sgd', 'mlp__warm_start': True e desconsiderar o kernel linar, que teve a menor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sigmoid_ = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"sigmoid\"],\n",
    "    \"svm__coef0\": [0.0, 0.5, 1],\n",
    "    \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-3],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_ = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"rbf\"],\n",
    "    \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-3],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_ = {\n",
    "    \"svm__C\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"svm__kernel\": [\"poly\"],\n",
    "    \"svm__coef0\": [0.0, 0.5, 1],\n",
    "    \"svm__degree\": [3, 4, 5],\n",
    "    \"svm__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__solver\": [\"sgd\"],\n",
    "    \"mlp__alpha\": [1e-3],\n",
    "    # \"mlp__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    # \"mlp__learning_rate_init\": [1e-2, 1e-3, 1e-4],\n",
    "    # \"mlp__max_iter\": [100, 200, 300],\n",
    "    # \"mlp__tol\": [1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['poly'], 'svm__coef0': [0.0, 0.5, 1], 'svm__degree': [3, 4, 5], 'svm__tol': [0.01, 0.001, 0.0001], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.001], 'mlp__warm_start': [True]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'mlp__activation': 'relu', 'mlp__alpha': 0.001, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__coef0': 0.0, 'svm__degree': 3, 'svm__kernel': 'poly', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.8566365007541478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      2637\n",
      "           1       0.16      0.85      0.28        91\n",
      "\n",
      "    accuracy                           0.85      2728\n",
      "   macro avg       0.58      0.85      0.60      2728\n",
      "weighted avg       0.97      0.85      0.90      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['rbf'], 'svm__tol': [0.01, 0.001, 0.0001], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.001], 'mlp__warm_start': [True]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'mlp__activation': 'logistic', 'mlp__alpha': 0.001, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__kernel': 'rbf', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.8565610859728506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.90      2637\n",
      "           1       0.15      0.90      0.26        91\n",
      "\n",
      "    accuracy                           0.83      2728\n",
      "   macro avg       0.57      0.86      0.58      2728\n",
      "weighted avg       0.97      0.83      0.88      2728\n",
      "\n",
      "Buscando com os parametros {'svm__C': [0.1, 0.5, 1.0, 1.5, 2.0], 'svm__kernel': ['sigmoid'], 'svm__coef0': [0.0, 0.5, 1], 'svm__tol': [0.01, 0.001, 0.0001], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__solver': ['sgd'], 'mlp__alpha': [0.001], 'mlp__warm_start': [True]}\n",
      "Melhores parâmetros: {'mlp__activation': 'logistic', 'mlp__alpha': 0.001, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__coef0': 0.0, 'svm__kernel': 'sigmoid', 'svm__tol': 0.01}\n",
      "Melhor f1: 0.8487933634992458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91      2637\n",
      "           1       0.16      0.90      0.28        91\n",
      "\n",
      "    accuracy                           0.84      2728\n",
      "   macro avg       0.58      0.87      0.59      2728\n",
      "weighted avg       0.97      0.84      0.89      2728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bianc\\Desktop\\Projeto-AM\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bests = SVMSearch(\n",
    "    [\n",
    "        svm_poly_,\n",
    "        svm_rbf_,\n",
    "        svm_sigmoid_\n",
    "    ],\n",
    "    X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor modelo foi com os parâmetros {'mlp__activation': 'relu', 'mlp__alpha': 0.001, 'mlp__solver': 'sgd', 'mlp__warm_start': True, 'svm__C': 0.5, 'svm__coef0': 0.0, 'svm__degree': 3, 'svm__kernel': 'poly', 'svm__tol': 0.01}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
